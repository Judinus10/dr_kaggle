{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4679312f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:00.714137Z",
     "iopub.status.busy": "2026-02-25T05:45:00.713861Z",
     "iopub.status.idle": "2026-02-25T05:45:01.197455Z",
     "shell.execute_reply": "2026-02-25T05:45:01.196578Z"
    },
    "papermill": {
     "duration": 0.489787,
     "end_time": "2026-02-25T05:45:01.199254",
     "exception": false,
     "start_time": "2026-02-25T05:45:00.709467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 25 05:45:00 2026       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   40C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b17160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:01.207234Z",
     "iopub.status.busy": "2026-02-25T05:45:01.206710Z",
     "iopub.status.idle": "2026-02-25T05:45:01.893094Z",
     "shell.execute_reply": "2026-02-25T05:45:01.892181Z"
    },
    "papermill": {
     "duration": 0.692208,
     "end_time": "2026-02-25T05:45:01.894565",
     "exception": false,
     "start_time": "2026-02-25T05:45:01.202357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lesion-aware-dr'...\r\n",
      "remote: Enumerating objects: 201, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (201/201), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (109/109), done.\u001b[K\r\n",
      "remote: Total 201 (delta 94), reused 178 (delta 71), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (201/201), 103.95 KiB | 4.00 MiB/s, done.\r\n",
      "Resolving deltas: 100% (94/94), done.\r\n",
      "/kaggle/working/lesion-aware-dr\n"
     ]
    }
   ],
   "source": [
    " !git clone https://github.com/Judinus10/lesion-aware-dr.git \n",
    "%cd lesion-aware-dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba02838b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:01.902841Z",
     "iopub.status.busy": "2026-02-25T05:45:01.902266Z",
     "iopub.status.idle": "2026-02-25T05:45:27.366717Z",
     "shell.execute_reply": "2026-02-25T05:45:27.366001Z"
    },
    "papermill": {
     "duration": 25.470493,
     "end_time": "2026-02-25T05:45:27.368471",
     "exception": false,
     "start_time": "2026-02-25T05:45:01.897978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets/mohlamin/resized-eyepacs-diabetic-retinopathy-dataset\r\n",
      "total 3.2M\r\n",
      "drwxr-xr-x 3 nobody nogroup    0 Feb 16 16:26 .\r\n",
      "drwxr-xr-x 3 root   root    4.0K Feb 25 05:44 ..\r\n",
      "-rw-r--r-- 1 nobody nogroup 1.6M Feb 16 16:26 all_labels.csv\r\n",
      "drwxr-xr-x 2 nobody nogroup    0 Feb 16 16:26 Images\r\n",
      "-rw-r--r-- 1 nobody nogroup 1.2M Feb 16 16:26 original_test_labels.csv\r\n",
      "-rw-r--r-- 1 nobody nogroup 455K Feb 16 16:26 original_train_labels.csv\r\n",
      "total 23G\r\n",
      "drwxr-xr-x 2 nobody nogroup    0 Feb 16 16:26 .\r\n",
      "drwxr-xr-x 3 nobody nogroup    0 Feb 16 16:26 ..\r\n",
      "-rw-r--r-- 1 nobody nogroup 218K Feb 16 16:19 10000_left.png\r\n",
      "-rw-r--r-- 1 nobody nogroup 214K Feb 16 16:19 10000_right.png\r\n",
      "-rw-r--r-- 1 nobody nogroup 216K Feb 16 16:19 10001_left.png\r\n",
      "-rw-r--r-- 1 nobody nogroup 211K Feb 16 16:19 10001_right.png\r\n",
      "-rw-r--r-- 1 nobody nogroup 186K Feb 16 16:19 10002_left.png\r\n",
      "-rw-r--r-- 1 nobody nogroup 297K Feb 16 16:19 10002_right.png\r\n",
      "-rw-r--r-- 1 nobody nogroup 210K Feb 16 16:19 10003_left.png\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT=\"/kaggle/input/datasets/mohlamin/resized-eyepacs-diabetic-retinopathy-dataset\"\n",
    "\n",
    "!echo $DATA_ROOT\n",
    "!ls -lah $DATA_ROOT\n",
    "!ls -lah $DATA_ROOT/Images | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbd3788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:27.377647Z",
     "iopub.status.busy": "2026-02-25T05:45:27.377059Z",
     "iopub.status.idle": "2026-02-25T05:45:27.381921Z",
     "shell.execute_reply": "2026-02-25T05:45:27.381105Z"
    },
    "papermill": {
     "duration": 0.011109,
     "end_time": "2026-02-25T05:45:27.383320",
     "exception": false,
     "start_time": "2026-02-25T05:45:27.372211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from pathlib import Path\n",
      "\n",
      "# --------------------\n",
      "# Paths\n",
      "# --------------------\n",
      "DATA_DIR = Path(r\"E:\\DR_related\\eyepacs\")\n",
      "LABELS_CSV = DATA_DIR / \"all_labels.csv\"\n",
      "IMAGES_DIR = DATA_DIR / \"Images\"\n",
      "\n",
      "OUT_TRAIN = DATA_DIR / \"train.csv\"\n",
      "OUT_VAL = DATA_DIR / \"val.csv\"\n",
      "\n",
      "# --------------------\n",
      "# Load labels\n",
      "# --------------------\n",
      "df = pd.read_csv(LABELS_CSV)\n",
      "print(\"Original columns:\", list(df.columns))\n",
      "\n",
      "# --------------------\n",
      "# Nor\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"/kaggle/working/lesion-aware-dr/scripts/make_split.py\")\n",
    "\n",
    "print(file_path.read_text()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b539c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:27.391248Z",
     "iopub.status.busy": "2026-02-25T05:45:27.390709Z",
     "iopub.status.idle": "2026-02-25T05:45:27.395627Z",
     "shell.execute_reply": "2026-02-25T05:45:27.394840Z"
    },
    "papermill": {
     "duration": 0.010314,
     "end_time": "2026-02-25T05:45:27.396994",
     "exception": false,
     "start_time": "2026-02-25T05:45:27.386680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Path updated\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"/kaggle/working/lesion-aware-dr/scripts/make_split.py\")\n",
    "\n",
    "text = file_path.read_text()\n",
    "\n",
    "text = text.replace(\n",
    "    r\"E:\\DR_related\\eyepacs\",\n",
    "    \"/kaggle/input/datasets/mohlamin/resized-eyepacs-diabetic-retinopathy-dataset\"\n",
    ")\n",
    "\n",
    "file_path.write_text(text)\n",
    "\n",
    "print(\"✅ Path updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c18363d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:27.405218Z",
     "iopub.status.busy": "2026-02-25T05:45:27.404592Z",
     "iopub.status.idle": "2026-02-25T05:45:27.409358Z",
     "shell.execute_reply": "2026-02-25T05:45:27.408651Z"
    },
    "papermill": {
     "duration": 0.010165,
     "end_time": "2026-02-25T05:45:27.410682",
     "exception": false,
     "start_time": "2026-02-25T05:45:27.400517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output paths updated\n"
     ]
    }
   ],
   "source": [
    "text = file_path.read_text()\n",
    "\n",
    "text = text.replace(\n",
    "    'DATA_DIR / \"train.csv\"',\n",
    "    'Path(\"/kaggle/working/train.csv\")'\n",
    ")\n",
    "\n",
    "text = text.replace(\n",
    "    'DATA_DIR / \"val.csv\"',\n",
    "    'Path(\"/kaggle/working/val.csv\")'\n",
    ")\n",
    "\n",
    "file_path.write_text(text)\n",
    "\n",
    "print(\"✅ Output paths updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e964ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:45:27.418809Z",
     "iopub.status.busy": "2026-02-25T05:45:27.418438Z",
     "iopub.status.idle": "2026-02-25T05:46:27.409488Z",
     "shell.execute_reply": "2026-02-25T05:46:27.408512Z"
    },
    "papermill": {
     "duration": 59.997138,
     "end_time": "2026-02-25T05:46:27.411301",
     "exception": false,
     "start_time": "2026-02-25T05:45:27.414163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/lesion-aware-dr\n",
      "Original columns: ['image', 'level', 'Usage']\r\n",
      "✅ All image files found.\r\n",
      "Saved: /kaggle/working/train.csv\r\n",
      "Saved: /kaggle/working/val.csv\r\n",
      "Train size: 70960\r\n",
      "Val size: 17740\r\n",
      "\r\n",
      "Train label distribution:\r\n",
      "label\r\n",
      "0    52273\r\n",
      "1     4964\r\n",
      "2    10522\r\n",
      "3     1670\r\n",
      "4     1531\r\n",
      "Name: count, dtype: int64\r\n",
      "\r\n",
      "Val label distribution:\r\n",
      "label\r\n",
      "0    13069\r\n",
      "1     1241\r\n",
      "2     2630\r\n",
      "3      417\r\n",
      "4      383\r\n",
      "Name: count, dtype: int64\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/lesion-aware-dr\n",
    "!python scripts/make_split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b353990d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.420726Z",
     "iopub.status.busy": "2026-02-25T05:46:27.420133Z",
     "iopub.status.idle": "2026-02-25T05:46:27.535780Z",
     "shell.execute_reply": "2026-02-25T05:46:27.534891Z"
    },
    "papermill": {
     "duration": 0.122363,
     "end_time": "2026-02-25T05:46:27.537546",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.415183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesion-aware-dr  __notebook__.ipynb  train.csv\tval.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01fd553b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.546401Z",
     "iopub.status.busy": "2026-02-25T05:46:27.546144Z",
     "iopub.status.idle": "2026-02-25T05:46:27.577062Z",
     "shell.execute_reply": "2026-02-25T05:46:27.576247Z"
    },
    "papermill": {
     "duration": 0.03722,
     "end_time": "2026-02-25T05:46:27.578527",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.541307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Patched paths + loss + sampler in base.yaml\n",
      "\n",
      "--- paths block ---\n",
      "paths:\n",
      "  data_dir: \"/kaggle/working\"\n",
      "  raw_dir: \"/kaggle/working\"\n",
      "  processed_dir: \"/kaggle/working\"\n",
      "  outputs_dir: \"/kaggle/working/outputs\"\n",
      "  checkpoints_dir: \"/kaggle/working/outputs/checkpoints\"\n",
      "\n",
      "\n",
      "model:\n",
      "  backbone: \"efficientnet_b0\"\n",
      "  num_classes: 5\n",
      "  pretrained: true\n",
      "\n",
      "data:\n",
      "  use_dummy: false\n",
      "  image_size: 224\n",
      "\n",
      "  train_csv: \"/content/drive/MyDrive/Lesion_aware_DR/eyepacs/train.csv\"\n",
      "  val_csv:   \"/content/drive/MyDrive/Lesion_aware_DR/eyepacs/val_clean.csv\"\n",
      "  image_dir: \"/content/eyepacs_images/Images\"\n",
      "  image_col: \"image_id\"\n",
      "  label_col: \"label\"\n",
      "\n",
      "  # Use ONE balancing method at a time.\n",
      "  # Here: sampler OFF, loss weights ON.\n",
      "\n",
      "--- data block (sampler lines) ---\n",
      "(no sampler lines found)\n",
      "\n",
      "--- loss block ---\n",
      "loss block not found\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "cfg_path = Path(\"/kaggle/working/lesion-aware-dr/configs/base.yaml\")\n",
    "text = cfg_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# ---------- 1) Force paths block ----------\n",
    "new_paths_block = \"\"\"paths:\n",
    "  data_dir: \"/kaggle/working\"\n",
    "  raw_dir: \"/kaggle/working\"\n",
    "  processed_dir: \"/kaggle/working\"\n",
    "  outputs_dir: \"/kaggle/working/outputs\"\n",
    "  checkpoints_dir: \"/kaggle/working/outputs/checkpoints\"\n",
    "\"\"\"\n",
    "\n",
    "# Replace existing paths block if present, else prepend it\n",
    "if re.search(r\"(?m)^paths:\\n(?:^[ \\t].*\\n)+\", text):\n",
    "    text = re.sub(r\"(?m)^paths:\\n(?:^[ \\t].*\\n)+\", new_paths_block + \"\\n\", text)\n",
    "else:\n",
    "    text = new_paths_block + \"\\n\" + text\n",
    "\n",
    "# ---------- 2) Force loss + sampler settings ----------\n",
    "desired = {\n",
    "    \"loss.name\": \"focal\",\n",
    "    \"loss.gamma\": \"1.5\",\n",
    "    \"loss.use_class_weights\": \"true\",\n",
    "    \"data.use_weighted_sampler\": \"false\",\n",
    "}\n",
    "\n",
    "def set_key(cfg_text: str, key: str, value: str) -> str:\n",
    "    section, field = key.split(\".\")\n",
    "\n",
    "    # Replace field inside existing section block\n",
    "    pattern = rf\"(?ms)^({section}:\\n(?:^[ \\t].*\\n)*)^[ \\t]*{field}:\\s*.*$\"\n",
    "    repl = rf\"\\1  {field}: {value}\"\n",
    "    if re.search(pattern, cfg_text):\n",
    "        return re.sub(pattern, repl, cfg_text)\n",
    "\n",
    "    # If section exists but field missing: insert after section header\n",
    "    sec_header = rf\"(?m)^{section}:\\s*$\"\n",
    "    if re.search(sec_header, cfg_text):\n",
    "        return re.sub(sec_header, f\"{section}:\\n  {field}: {value}\", cfg_text, count=1)\n",
    "\n",
    "    # If section missing entirely: append section at end\n",
    "    return cfg_text.rstrip() + f\"\\n\\n{section}:\\n  {field}: {value}\\n\"\n",
    "\n",
    "for k, v in desired.items():\n",
    "    text = set_key(text, k, v)\n",
    "\n",
    "cfg_path.write_text(text, encoding=\"utf-8\")\n",
    "print(\"✅ Patched paths + loss + sampler in base.yaml\")\n",
    "\n",
    "# ---------- 3) Quick verification print ----------\n",
    "print(\"\\n--- paths block ---\")\n",
    "m = re.search(r\"(?ms)^paths:\\n(?:^[ \\t].*\\n)+\", text)\n",
    "print(m.group(0).strip() if m else \"paths block not found\")\n",
    "\n",
    "print(\"\\n--- data block (sampler lines) ---\")\n",
    "m = re.search(r\"(?ms)^data:\\n(?:^[ \\t].*\\n)+\", text)\n",
    "if m:\n",
    "    # print only key lines\n",
    "    data_lines = [ln for ln in m.group(0).splitlines() if \"use_weighted_sampler\" in ln or \"sampler_mode\" in ln]\n",
    "    print(\"\\n\".join(data_lines) if data_lines else \"(no sampler lines found)\")\n",
    "else:\n",
    "    print(\"data block not found\")\n",
    "\n",
    "print(\"\\n--- loss block ---\")\n",
    "m = re.search(r\"(?ms)^loss:\\n(?:^[ \\t].*\\n)+\", text)\n",
    "print(m.group(0).strip() if m else \"loss block not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c222ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.587325Z",
     "iopub.status.busy": "2026-02-25T05:46:27.586748Z",
     "iopub.status.idle": "2026-02-25T05:46:27.592282Z",
     "shell.execute_reply": "2026-02-25T05:46:27.591762Z"
    },
    "papermill": {
     "duration": 0.011331,
     "end_time": "2026-02-25T05:46:27.593630",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.582299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Patched paths block in base.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "cfg_path = Path(\"/kaggle/working/lesion-aware-dr/configs/base.yaml\")\n",
    "text = cfg_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "new_paths_block = \"\"\"paths:\n",
    "  data_dir: \"/kaggle/working\"\n",
    "  raw_dir: \"/kaggle/working\"\n",
    "  processed_dir: \"/kaggle/working\"\n",
    "  outputs_dir: \"/kaggle/working/outputs\"\n",
    "  checkpoints_dir: \"/kaggle/working/outputs/checkpoints\"\n",
    "\"\"\"\n",
    "\n",
    "# Replace existing paths: block if present, else prepend it.\n",
    "if re.search(r\"(?m)^paths:\\n(?:^[ \\t].*\\n)+\", text):\n",
    "    text = re.sub(r\"(?m)^paths:\\n(?:^[ \\t].*\\n)+\", new_paths_block + \"\\n\", text)\n",
    "else:\n",
    "    text = new_paths_block + \"\\n\" + text\n",
    "\n",
    "cfg_path.write_text(text, encoding=\"utf-8\")\n",
    "print(\"✅ Patched paths block in base.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d245dd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.602246Z",
     "iopub.status.busy": "2026-02-25T05:46:27.601704Z",
     "iopub.status.idle": "2026-02-25T05:46:27.726719Z",
     "shell.execute_reply": "2026-02-25T05:46:27.725834Z"
    },
    "papermill": {
     "duration": 0.131153,
     "end_time": "2026-02-25T05:46:27.728479",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.597326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_name: \"lesion_aware_dr\"\r\n",
      "run_name: \"efficientnet_cb_focal\"\r\n",
      "\r\n",
      "paths:\r\n",
      "  data_dir: \"/kaggle/working\"\r\n",
      "  raw_dir: \"/kaggle/working\"\r\n",
      "  processed_dir: \"/kaggle/working\"\r\n",
      "  outputs_dir: \"/kaggle/working/outputs\"\r\n",
      "  checkpoints_dir: \"/kaggle/working/outputs/checkpoints\"\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model:\r\n",
      "  backbone: \"efficientnet_b0\"\r\n",
      "  num_classes: 5\r\n",
      "  pretrained: true\r\n",
      "\r\n",
      "data:\r\n",
      "  use_dummy: false\r\n",
      "  image_size: 224\r\n",
      "\r\n",
      "  train_csv: \"/content/drive/MyDrive/Lesion_aware_DR/eyepacs/train.csv\"\r\n",
      "  val_csv:   \"/content/drive/MyDrive/Lesion_aware_DR/eyepacs/val_clean.csv\"\r\n",
      "  image_dir: \"/content/eyepacs_images/Images\"\r\n",
      "  image_col: \"image_id\"\r\n",
      "  label_col: \"label\"\r\n",
      "\r\n",
      "  # Use ONE balancing method at a time.\r\n",
      "  # Here: sampler OFF, loss weights ON.\r\n",
      "  use_weighted_sampler: false"
     ]
    }
   ],
   "source": [
    "!sed -n '1,120p' /kaggle/working/lesion-aware-dr/configs/base.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb5e9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.737986Z",
     "iopub.status.busy": "2026-02-25T05:46:27.737670Z",
     "iopub.status.idle": "2026-02-25T05:46:27.746643Z",
     "shell.execute_reply": "2026-02-25T05:46:27.745967Z"
    },
    "papermill": {
     "duration": 0.015559,
     "end_time": "2026-02-25T05:46:27.748095",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.732536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ requirements fixed & converted to UTF-8\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "req_path = Path(\"/kaggle/working/lesion-aware-dr/requirements_local.txt\")\n",
    "\n",
    "# try reading with utf-16 fallback\n",
    "try:\n",
    "    text = req_path.read_text(encoding=\"utf-8\")\n",
    "except UnicodeDecodeError:\n",
    "    text = req_path.read_text(encoding=\"utf-16\")\n",
    "\n",
    "lines = text.splitlines()\n",
    "\n",
    "remove_keys = [\n",
    "    \"torch==\",\n",
    "    \"torchvision==\",\n",
    "    \"torchaudio==\",\n",
    "    \"opencv-python==\",\n",
    "]\n",
    "\n",
    "cleaned = [line for line in lines if not any(k in line for k in remove_keys)]\n",
    "\n",
    "needed = [\"grad-cam\", \"torchmetrics\", \"einops\"]\n",
    "\n",
    "for pkg in needed:\n",
    "    if not any(pkg in line for line in cleaned):\n",
    "        cleaned.append(pkg)\n",
    "\n",
    "req_path.write_text(\"\\n\".join(cleaned), encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ requirements fixed & converted to UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2a95b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.756982Z",
     "iopub.status.busy": "2026-02-25T05:46:27.756737Z",
     "iopub.status.idle": "2026-02-25T05:46:27.766040Z",
     "shell.execute_reply": "2026-02-25T05:46:27.765292Z"
    },
    "papermill": {
     "duration": 0.015655,
     "end_time": "2026-02-25T05:46:27.767651",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.751996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created: /kaggle/working/lesion-aware-dr/src/data/dr_datamodule.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "repo = Path(\"/kaggle/working/lesion-aware-dr\")\n",
    "\n",
    "data_dir = repo / \"src\" / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# make it a package\n",
    "(data_dir / \"__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "code = r'''from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# ---------- Dummy dataset for quick testing ----------\n",
    "\n",
    "class DummyDRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Returns random images & labels.\n",
    "    Use only when cfg.data.use_dummy = true.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples: int, num_classes: int, image_size: int):\n",
    "        self.num_samples = int(num_samples)\n",
    "        self.num_classes = int(num_classes)\n",
    "        self.image_size = int(image_size)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        image = torch.rand(3, self.image_size, self.image_size)\n",
    "        label = torch.randint(0, self.num_classes, (1,)).item()\n",
    "        return {\"image\": image, \"label\": torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "\n",
    "# ---------- Real dataset for APTOS / EyePACS / etc. ----------\n",
    "\n",
    "class DRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic DR dataset reading from CSV:\n",
    "      - image filename column (e.g., '16028_left.png')\n",
    "      - integer label column (0..num_classes-1)\n",
    "\n",
    "    Robust to corrupted images: retries a few times and then errors clearly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        images_dir: str,\n",
    "        image_col: str,\n",
    "        label_col: str,\n",
    "        image_size: int = 224,\n",
    "        augment: bool = False,\n",
    "        max_decode_retries: int = 20,\n",
    "        log_bad_every: int = 50,\n",
    "    ):\n",
    "        self.df = pd.read_csv(csv_path).reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.image_col = str(image_col)\n",
    "        self.label_col = str(label_col)\n",
    "        self.image_size = int(image_size)\n",
    "\n",
    "        self.max_decode_retries = int(max_decode_retries)\n",
    "        self.log_bad_every = int(log_bad_every)\n",
    "        self.bad_count = 0\n",
    "\n",
    "        # ✅ EfficientNet pretrained expects ImageNet normalization\n",
    "        imagenet_mean = (0.485, 0.456, 0.406)\n",
    "        imagenet_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "        if augment:\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.Resize(image_size, image_size),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.RandomBrightnessContrast(p=0.4),\n",
    "                    # Replace ShiftScaleRotate with Affine (newer albumentations recommendation)\n",
    "                    A.Affine(\n",
    "                        scale=(0.95, 1.05),\n",
    "                        translate_percent=(0.0, 0.05),\n",
    "                        rotate=(-15, 15),\n",
    "                        p=0.5,\n",
    "                        mode=cv2.BORDER_REFLECT_101,\n",
    "                    ),\n",
    "                    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.Resize(image_size, image_size),\n",
    "                    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def _read_image(self, img_path: Path):\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            return None\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        for _ in range(self.max_decode_retries):\n",
    "            row = self.df.iloc[idx]\n",
    "            fname = str(row[self.image_col])\n",
    "            img_path = self.images_dir / fname\n",
    "\n",
    "            image = self._read_image(img_path)\n",
    "\n",
    "            if image is not None:\n",
    "                label = int(row[self.label_col])\n",
    "                augmented = self.transform(image=image)\n",
    "                return {\n",
    "                    \"image\": augmented[\"image\"],\n",
    "                    \"label\": torch.tensor(label, dtype=torch.long),\n",
    "                }\n",
    "\n",
    "            # Bad image encountered\n",
    "            self.bad_count += 1\n",
    "            if self.log_bad_every > 0 and self.bad_count % self.log_bad_every == 0:\n",
    "                print(f\"[WARN] Skipped {self.bad_count} corrupted images so far. Latest: {img_path}\")\n",
    "\n",
    "            idx = random.randint(0, len(self.df) - 1)\n",
    "\n",
    "        raise RuntimeError(\n",
    "            f\"Too many unreadable images encountered (>{self.max_decode_retries} retries). \"\n",
    "            f\"Check dataset integrity and image_dir. Last attempted: {img_path}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ---------- DataModule wrapper ----------\n",
    "\n",
    "class DRDataModule:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.batch_size = int(cfg.training.batch_size)\n",
    "        self.num_workers = int(cfg.training.num_workers)\n",
    "        self.num_classes = int(cfg.model.num_classes)\n",
    "        self.image_size = int(cfg.data.image_size)\n",
    "\n",
    "        self.use_dummy = bool(cfg.data.get(\"use_dummy\", False))\n",
    "\n",
    "        # Optional sampler (only if you intentionally enable it in YAML)\n",
    "        self.use_weighted_sampler = bool(cfg.data.get(\"use_weighted_sampler\", False))\n",
    "        self.sampler_mode = str(cfg.data.get(\"sampler_mode\", \"inverse\")).lower()\n",
    "\n",
    "    def _pin_memory(self) -> bool:\n",
    "        return torch.cuda.is_available()\n",
    "\n",
    "    def _build_weighted_sampler_from_csv(self, csv_path: str, label_col: str) -> WeightedRandomSampler:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        labels = df[label_col].astype(int).values\n",
    "\n",
    "        class_counts = np.bincount(labels, minlength=self.num_classes).astype(np.float32)\n",
    "        class_counts = np.maximum(class_counts, 1.0)\n",
    "\n",
    "        # inverse-frequency sampling\n",
    "        class_weights = 1.0 / class_counts\n",
    "        sample_weights = class_weights[labels]\n",
    "        sample_weights = torch.tensor(sample_weights, dtype=torch.double)\n",
    "\n",
    "        return WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True,\n",
    "        )\n",
    "\n",
    "    # ---- Dataloaders ----\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        if self.use_dummy:\n",
    "            ds = DummyDRDataset(\n",
    "                num_samples=256,\n",
    "                num_classes=self.num_classes,\n",
    "                image_size=self.image_size,\n",
    "            )\n",
    "            return DataLoader(\n",
    "                ds,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=self._pin_memory(),\n",
    "            )\n",
    "\n",
    "        ds = DRDataset(\n",
    "            csv_path=self.cfg.data.train_csv,\n",
    "            images_dir=self.cfg.data.image_dir,\n",
    "            image_col=self.cfg.data.image_col,\n",
    "            label_col=self.cfg.data.label_col,\n",
    "            image_size=self.image_size,\n",
    "            augment=True,\n",
    "            max_decode_retries=30,\n",
    "            log_bad_every=50,\n",
    "        )\n",
    "\n",
    "        if self.use_weighted_sampler:\n",
    "            sampler = self._build_weighted_sampler_from_csv(\n",
    "                csv_path=self.cfg.data.train_csv,\n",
    "                label_col=self.cfg.data.label_col,\n",
    "            )\n",
    "            return DataLoader(\n",
    "                ds,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,  # sampler + shuffle cannot both be True\n",
    "                sampler=sampler,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=self._pin_memory(),\n",
    "            )\n",
    "\n",
    "        return DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self._pin_memory(),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        if self.use_dummy:\n",
    "            ds = DummyDRDataset(\n",
    "                num_samples=64,\n",
    "                num_classes=self.num_classes,\n",
    "                image_size=self.image_size,\n",
    "            )\n",
    "        else:\n",
    "            ds = DRDataset(\n",
    "                csv_path=self.cfg.data.val_csv,\n",
    "                images_dir=self.cfg.data.image_dir,\n",
    "                image_col=self.cfg.data.image_col,\n",
    "                label_col=self.cfg.data.label_col,\n",
    "                image_size=self.image_size,\n",
    "                augment=False,\n",
    "                max_decode_retries=30,\n",
    "                log_bad_every=50,\n",
    "            )\n",
    "\n",
    "        return DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self._pin_memory(),\n",
    "        )\n",
    "'''\n",
    "\n",
    "(data_dir / \"dr_datamodule.py\").write_text(code, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Created:\", data_dir / \"dr_datamodule.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0492d115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.776754Z",
     "iopub.status.busy": "2026-02-25T05:46:27.776205Z",
     "iopub.status.idle": "2026-02-25T05:46:27.780307Z",
     "shell.execute_reply": "2026-02-25T05:46:27.779679Z"
    },
    "papermill": {
     "duration": 0.009966,
     "end_time": "2026-02-25T05:46:27.781568",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.771602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albucore==0.0.24\n",
      "albumentations==2.0.8\n",
      "altair==5.5.0\n",
      "annotated-types==0.7.0\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==4.12.0\n",
      "attrs==25.4.0\n",
      "blinker==1.9.0\n",
      "cachetools==6.2.2\n",
      "certifi==2025.11.12\n",
      "charset-norma\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(\"/kaggle/working/lesion-aware-dr/requirements_local.txt\")\n",
    "print(p.read_text()[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca93054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:46:27.790658Z",
     "iopub.status.busy": "2026-02-25T05:46:27.790041Z",
     "iopub.status.idle": "2026-02-25T05:47:43.655460Z",
     "shell.execute_reply": "2026-02-25T05:47:43.654496Z"
    },
    "papermill": {
     "duration": 75.871842,
     "end_time": "2026-02-25T05:47:43.657367",
     "exception": false,
     "start_time": "2026-02-25T05:46:27.785525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.1/516.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.0/425.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.3/395.3 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.3/406.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.1/653.1 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.2/231.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.31.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-adk 1.21.0 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\r\n",
      "transformers 5.2.0 requires huggingface-hub<2.0,>=1.3.0, but you have huggingface-hub 1.1.6 which is incompatible.\r\n",
      "ydata-profiling 4.18.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "google-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.5.1, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\r\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.1 which is incompatible.\r\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\r\n",
      "gradio 5.50.0 requires pydantic<=2.12.3,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -r /kaggle/working/lesion-aware-dr/requirements_local.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b745d95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:47:43.671172Z",
     "iopub.status.busy": "2026-02-25T05:47:43.670878Z",
     "iopub.status.idle": "2026-02-25T05:47:47.678282Z",
     "shell.execute_reply": "2026-02-25T05:47:47.677410Z"
    },
    "papermill": {
     "duration": 4.016089,
     "end_time": "2026-02-25T05:47:47.679717",
     "exception": false,
     "start_time": "2026-02-25T05:47:43.663628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e5d0ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:47:47.694091Z",
     "iopub.status.busy": "2026-02-25T05:47:47.693499Z",
     "iopub.status.idle": "2026-02-25T05:47:47.699241Z",
     "shell.execute_reply": "2026-02-25T05:47:47.698517Z"
    },
    "papermill": {
     "duration": 0.014209,
     "end_time": "2026-02-25T05:47:47.700540",
     "exception": false,
     "start_time": "2026-02-25T05:47:47.686331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rewrote base.yaml cleanly: /kaggle/working/lesion-aware-dr/configs/base.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "cfg_path = Path(\"/kaggle/working/lesion-aware-dr/configs/base.yaml\")\n",
    "\n",
    "clean_yaml = \"\"\"project_name: \"lesion_aware_dr\"\n",
    "run_name: \"efficientnet_focal_g15_cw\"\n",
    "\n",
    "paths:\n",
    "  data_dir: \"/kaggle/working\"\n",
    "  raw_dir: \"/kaggle/working\"\n",
    "  processed_dir: \"/kaggle/working\"\n",
    "  outputs_dir: \"/kaggle/working/outputs\"\n",
    "  checkpoints_dir: \"/kaggle/working/outputs/checkpoints\"\n",
    "\n",
    "model:\n",
    "  backbone: \"efficientnet_b0\"\n",
    "  num_classes: 5\n",
    "  pretrained: true\n",
    "\n",
    "data:\n",
    "  use_dummy: false\n",
    "  image_size: 224\n",
    "\n",
    "  train_csv: \"/kaggle/working/train.csv\"\n",
    "  val_csv:   \"/kaggle/working/val.csv\"\n",
    "  image_dir: \"/kaggle/input/datasets/mohlamin/resized-eyepacs-diabetic-retinopathy-dataset/Images\"\n",
    "  image_col: \"image_id\"\n",
    "  label_col: \"label\"\n",
    "\n",
    "  use_weighted_sampler: false\n",
    "  sampler_mode: \"inverse\"\n",
    "\n",
    "training:\n",
    "  seed: 42\n",
    "  epochs: 12\n",
    "  batch_size: 16\n",
    "  num_workers: 2\n",
    "  lr: 1e-4\n",
    "  weight_decay: 1e-5\n",
    "  optimizer: \"adamw\"\n",
    "  scheduler: \"cosine\"\n",
    "\n",
    "logging:\n",
    "  use_wandb: false\n",
    "  wandb_project: \"lesion_aware_dr\"\n",
    "  wandb_entity: null\n",
    "\n",
    "loss:\n",
    "  name: \"focal\"\n",
    "  beta: 0.999\n",
    "  gamma: 1.5\n",
    "  alpha_mode: \"effective\"\n",
    "  reduction: \"mean\"\n",
    "  use_class_weights: true\n",
    "\"\"\"\n",
    "\n",
    "cfg_path.write_text(clean_yaml, encoding=\"utf-8\")\n",
    "print(\"✅ Rewrote base.yaml cleanly:\", cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d61603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T05:47:47.714256Z",
     "iopub.status.busy": "2026-02-25T05:47:47.713969Z",
     "iopub.status.idle": "2026-02-25T07:41:38.069475Z",
     "shell.execute_reply": "2026-02-25T07:41:38.068583Z"
    },
    "papermill": {
     "duration": 6830.364683,
     "end_time": "2026-02-25T07:41:38.071329",
     "exception": false,
     "start_time": "2026-02-25T05:47:47.706646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/lesion-aware-dr\n",
      "[2026-02-25 05:47:58] [INFO] Starting training script\r\n",
      "[2026-02-25 05:47:58] [INFO] Using device: cuda\r\n",
      "[2026-02-25 05:47:58] [INFO] [RUN DIR] New run folder: /kaggle/working/outputs/2026-02-25\r\n",
      "[2026-02-25 05:47:58] [INFO] [RUN DIR] Checkpoints folder: /kaggle/working/outputs/2026-02-25/checkpoints\r\n",
      "[2026-02-25 05:47:58] [INFO] Config:\r\n",
      "project_name: lesion_aware_dr\r\n",
      "run_name: efficientnet_focal_g15_cw\r\n",
      "paths:\r\n",
      "  data_dir: /kaggle/working\r\n",
      "  raw_dir: /kaggle/working\r\n",
      "  processed_dir: /kaggle/working\r\n",
      "  outputs_dir: /kaggle/working/outputs/2026-02-25\r\n",
      "  checkpoints_dir: /kaggle/working/outputs/2026-02-25/checkpoints\r\n",
      "model:\r\n",
      "  backbone: efficientnet_b0\r\n",
      "  num_classes: 5\r\n",
      "  pretrained: true\r\n",
      "data:\r\n",
      "  use_dummy: false\r\n",
      "  image_size: 224\r\n",
      "  train_csv: /kaggle/working/train.csv\r\n",
      "  val_csv: /kaggle/working/val.csv\r\n",
      "  image_dir: /kaggle/input/datasets/mohlamin/resized-eyepacs-diabetic-retinopathy-dataset/Images\r\n",
      "  image_col: image_id\r\n",
      "  label_col: label\r\n",
      "  use_weighted_sampler: false\r\n",
      "  sampler_mode: inverse\r\n",
      "training:\r\n",
      "  seed: 42\r\n",
      "  epochs: 12\r\n",
      "  batch_size: 16\r\n",
      "  num_workers: 2\r\n",
      "  lr: 0.0001\r\n",
      "  weight_decay: 1.0e-05\r\n",
      "  optimizer: adamw\r\n",
      "  scheduler: cosine\r\n",
      "logging:\r\n",
      "  use_wandb: false\r\n",
      "  wandb_project: lesion_aware_dr\r\n",
      "  wandb_entity: null\r\n",
      "loss:\r\n",
      "  name: focal\r\n",
      "  beta: 0.999\r\n",
      "  gamma: 1.5\r\n",
      "  alpha_mode: effective\r\n",
      "  reduction: mean\r\n",
      "  use_class_weights: true\r\n",
      "\r\n",
      "/kaggle/working/lesion-aware-dr/src/data/dr_datamodule.py:81: UserWarning: Argument(s) 'mode' are not valid for transform Affine\r\n",
      "  A.Affine(\r\n",
      "[2026-02-25 05:47:58] [INFO] Train samples: 70960\r\n",
      "[2026-02-25 05:47:58] [INFO] Val samples:   17740\r\n",
      "[2026-02-25 05:47:58] [INFO] Train batches: 4435\r\n",
      "[2026-02-25 05:47:58] [INFO] Val batches:   1109\r\n",
      "model.safetensors: 100%|███████████████████| 21.4M/21.4M [00:00<00:00, 37.1MB/s]\r\n",
      "/kaggle/working/lesion-aware-dr/src/train.py:251: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\r\n",
      "Epoch 1/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 1/12 [TRAIN]:  13%|▏| 594/4435 [01:26<09:31,  6.72it/s, loss=0.5311, lr=1.libpng error: Read Error\r\n",
      "Epoch 1/12 [TRAIN]: 100%|█| 4435/4435 [10:44<00:00,  6.88it/s, loss=0.4938, lr=1\r\n",
      "Epoch 1/12 [VAL]: 100%|████| 1109/1109 [02:21<00:00,  7.82it/s, val_loss=0.1450]\r\n",
      "[2026-02-25 06:01:06] [INFO] Epoch [1/12] train_loss=0.4815 val_loss=0.3409 val_acc=0.7877 val_f1=0.4196 (best_f1=-1.0000, best_loss=inf)\r\n",
      "[2026-02-25 06:01:06] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.4196)\r\n",
      "[2026-02-25 06:01:06] [INFO] ✅ Saved best val-loss model for THIS RUN (val_loss=0.3409)\r\n",
      "Epoch 2/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 2/12 [TRAIN]:  93%|▉| 4136/4435 [06:42<00:28, 10.46it/s, loss=0.2638, lr=9libpng error: Read Error\r\n",
      "Epoch 2/12 [TRAIN]: 100%|█| 4435/4435 [07:11<00:00, 10.28it/s, loss=0.3174, lr=9\r\n",
      "Epoch 2/12 [VAL]: 100%|████| 1109/1109 [01:31<00:00, 12.15it/s, val_loss=0.1838]\r\n",
      "[2026-02-25 06:09:49] [INFO] Epoch [2/12] train_loss=0.3332 val_loss=0.3161 val_acc=0.7966 val_f1=0.4742 (best_f1=0.4196, best_loss=0.3409)\r\n",
      "[2026-02-25 06:09:49] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.4742)\r\n",
      "[2026-02-25 06:09:49] [INFO] ✅ Saved best val-loss model for THIS RUN (val_loss=0.3161)\r\n",
      "Epoch 3/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 3/12 [TRAIN]:   3%| | 147/4435 [00:14<07:02, 10.14it/s, loss=0.3311, lr=9.libpng error: Read Error\r\n",
      "Epoch 3/12 [TRAIN]: 100%|█| 4435/4435 [07:17<00:00, 10.13it/s, loss=0.1785, lr=9\r\n",
      "Epoch 3/12 [VAL]: 100%|████| 1109/1109 [01:38<00:00, 11.31it/s, val_loss=0.2393]\r\n",
      "[2026-02-25 06:18:46] [INFO] Epoch [3/12] train_loss=0.3059 val_loss=0.2992 val_acc=0.8035 val_f1=0.4920 (best_f1=0.4742, best_loss=0.3161)\r\n",
      "[2026-02-25 06:18:46] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.4920)\r\n",
      "[2026-02-25 06:18:46] [INFO] ✅ Saved best val-loss model for THIS RUN (val_loss=0.2992)\r\n",
      "Epoch 4/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 4/12 [TRAIN]:  63%|▋| 2785/4435 [04:41<02:44, 10.00it/s, loss=0.1630, lr=8libpng error: Read Error\r\n",
      "Epoch 4/12 [TRAIN]: 100%|█| 4435/4435 [07:29<00:00,  9.87it/s, loss=0.1726, lr=8\r\n",
      "Epoch 4/12 [VAL]: 100%|████| 1109/1109 [01:37<00:00, 11.33it/s, val_loss=0.2126]\r\n",
      "[2026-02-25 06:27:53] [INFO] Epoch [4/12] train_loss=0.2835 val_loss=0.2928 val_acc=0.8117 val_f1=0.4920 (best_f1=0.4920, best_loss=0.2992)\r\n",
      "[2026-02-25 06:27:54] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.4920)\r\n",
      "[2026-02-25 06:27:54] [INFO] ✅ Saved best val-loss model for THIS RUN (val_loss=0.2928)\r\n",
      "Epoch 5/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 5/12 [TRAIN]:  90%|▉| 3999/4435 [06:39<00:42, 10.18it/s, loss=0.1831, lr=7libpng error: Read Error\r\n",
      "Epoch 5/12 [TRAIN]: 100%|█| 4435/4435 [07:23<00:00, 10.00it/s, loss=0.1336, lr=7\r\n",
      "Epoch 5/12 [VAL]: 100%|████| 1109/1109 [01:36<00:00, 11.49it/s, val_loss=0.2124]\r\n",
      "[2026-02-25 06:36:54] [INFO] Epoch [5/12] train_loss=0.2647 val_loss=0.2901 val_acc=0.8154 val_f1=0.4930 (best_f1=0.4920, best_loss=0.2928)\r\n",
      "[2026-02-25 06:36:54] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.4930)\r\n",
      "[2026-02-25 06:36:55] [INFO] ✅ Saved best val-loss model for THIS RUN (val_loss=0.2901)\r\n",
      "Epoch 6/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 6/12 [TRAIN]:  40%|▍| 1754/4435 [02:53<04:23, 10.18it/s, loss=0.2313, lr=6libpng error: Read Error\r\n",
      "Epoch 6/12 [TRAIN]: 100%|█| 4435/4435 [07:30<00:00,  9.84it/s, loss=0.2584, lr=6\r\n",
      "Epoch 6/12 [VAL]: 100%|████| 1109/1109 [01:43<00:00, 10.69it/s, val_loss=0.1888]\r\n",
      "[2026-02-25 06:46:09] [INFO] Epoch [6/12] train_loss=0.2447 val_loss=0.2957 val_acc=0.8141 val_f1=0.4936 (best_f1=0.4930, best_loss=0.2901)\r\n",
      "[2026-02-25 06:46:09] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.4936)\r\n",
      "Epoch 7/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 7/12 [TRAIN]:  41%|▍| 1821/4435 [03:07<04:29,  9.70it/s, loss=0.4963, lr=5libpng error: Read Error\r\n",
      "Epoch 7/12 [TRAIN]: 100%|█| 4435/4435 [07:37<00:00,  9.69it/s, loss=0.1131, lr=5\r\n",
      "Epoch 7/12 [VAL]: 100%|████| 1109/1109 [01:38<00:00, 11.30it/s, val_loss=0.1870]\r\n",
      "[2026-02-25 06:55:25] [INFO] Epoch [7/12] train_loss=0.2240 val_loss=0.3045 val_acc=0.8060 val_f1=0.5088 (best_f1=0.4936, best_loss=0.2901)\r\n",
      "[2026-02-25 06:55:26] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.5088)\r\n",
      "Epoch 8/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 8/12 [TRAIN]:   7%| | 303/4435 [00:31<07:47,  8.83it/s, loss=0.3649, lr=3.libpng error: Read Error\r\n",
      "Epoch 8/12 [TRAIN]: 100%|█| 4435/4435 [07:36<00:00,  9.72it/s, loss=0.1542, lr=3\r\n",
      "Epoch 8/12 [VAL]: 100%|████| 1109/1109 [01:33<00:00, 11.87it/s, val_loss=0.2014]\r\n",
      "[2026-02-25 07:04:35] [INFO] Epoch [8/12] train_loss=0.2005 val_loss=0.3090 val_acc=0.8064 val_f1=0.5211 (best_f1=0.5088, best_loss=0.2901)\r\n",
      "[2026-02-25 07:04:36] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.5211)\r\n",
      "Epoch 9/12 [TRAIN]:   0%|                              | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 9/12 [TRAIN]:  42%|▍| 1851/4435 [03:10<04:28,  9.63it/s, loss=0.3236, lr=2libpng error: Read Error\r\n",
      "Epoch 9/12 [TRAIN]: 100%|█| 4435/4435 [07:35<00:00,  9.73it/s, loss=0.0596, lr=2\r\n",
      "Epoch 9/12 [VAL]: 100%|████| 1109/1109 [01:32<00:00, 11.93it/s, val_loss=0.1764]\r\n",
      "[2026-02-25 07:13:44] [INFO] Epoch [9/12] train_loss=0.1797 val_loss=0.3342 val_acc=0.8020 val_f1=0.5240 (best_f1=0.5211, best_loss=0.2901)\r\n",
      "[2026-02-25 07:13:45] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.5240)\r\n",
      "Epoch 10/12 [TRAIN]:   0%|                             | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 10/12 [TRAIN]:  60%|▌| 2657/4435 [04:29<02:56, 10.05it/s, loss=0.0424, lr=libpng error: Read Error\r\n",
      "Epoch 10/12 [TRAIN]: 100%|█| 4435/4435 [07:30<00:00,  9.85it/s, loss=0.1337, lr=\r\n",
      "Epoch 10/12 [VAL]: 100%|███| 1109/1109 [01:38<00:00, 11.22it/s, val_loss=0.2230]\r\n",
      "[2026-02-25 07:22:54] [INFO] Epoch [10/12] train_loss=0.1639 val_loss=0.3430 val_acc=0.8045 val_f1=0.5175 (best_f1=0.5240, best_loss=0.2901)\r\n",
      "Epoch 11/12 [TRAIN]:   0%|                             | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 11/12 [TRAIN]:   0%| | 1/4435 [00:00<27:01,  2.73it/s, loss=0.2115, lr=6.7libpng error: Read Error\r\n",
      "Epoch 11/12 [TRAIN]: 100%|█| 4435/4435 [07:37<00:00,  9.70it/s, loss=0.1348, lr=\r\n",
      "Epoch 11/12 [VAL]: 100%|███| 1109/1109 [01:38<00:00, 11.20it/s, val_loss=0.1973]\r\n",
      "[2026-02-25 07:32:10] [INFO] Epoch [11/12] train_loss=0.1494 val_loss=0.3563 val_acc=0.8033 val_f1=0.5187 (best_f1=0.5240, best_loss=0.2901)\r\n",
      "Epoch 12/12 [TRAIN]:   0%|                             | 0/4435 [00:00<?, ?it/s]/kaggle/working/lesion-aware-dr/src/train.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\r\n",
      "Epoch 12/12 [TRAIN]:  43%|▍| 1892/4435 [03:19<04:20,  9.78it/s, loss=0.1731, lr=libpng error: Read Error\r\n",
      "Epoch 12/12 [TRAIN]: 100%|█| 4435/4435 [07:44<00:00,  9.56it/s, loss=0.1845, lr=\r\n",
      "Epoch 12/12 [VAL]: 100%|███| 1109/1109 [01:40<00:00, 11.04it/s, val_loss=0.2021]\r\n",
      "[2026-02-25 07:41:35] [INFO] Epoch [12/12] train_loss=0.1455 val_loss=0.3569 val_acc=0.7948 val_f1=0.5279 (best_f1=0.5240, best_loss=0.2901)\r\n",
      "[2026-02-25 07:41:35] [INFO] ✅ Saved best macro-F1 model for THIS RUN (val_f1=0.5279)\r\n",
      "[2026-02-25 07:41:35] [INFO] Training completed. Run saved at: /kaggle/working/outputs/2026-02-25\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/lesion-aware-dr\n",
    "!python -m src.train --cfg_path configs/base.yaml"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13032739,
     "datasetId": 7859837,
     "sourceId": 12459609,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7003.319189,
   "end_time": "2026-02-25T07:41:41.519530",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-25T05:44:58.200341",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
